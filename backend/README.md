# ğŸ¤– Backend - Sistema RAG para Chatbot

Este backend implementa un sistema RAG (Retrieval-Augmented Generation) para un chatbot inteligente que responde exclusivamente sobre la informaciÃ³n de tu portafolio profesional. Integra datos de mÃºltiples fuentes y utiliza Google Vertex AI para bÃºsqueda semÃ¡ntica y generaciÃ³n de respuestas contextuales.

## ğŸš€ CaracterÃ­sticas Principales

- ğŸ¤– **Sistema RAG Avanzado** - Retrieval-Augmented Generation con bÃºsqueda semÃ¡ntica
- ğŸ” **BÃºsqueda Vectorial** - IntegraciÃ³n con Google Vertex AI Vector Search
- ğŸ’¬ **Chatbot Inteligente** - Respuestas contextuales basadas en el portafolio
- ğŸ” **API RESTful** - FastAPI con documentaciÃ³n automÃ¡tica
- ğŸ“Š **Pipeline de Ingesta** - Procesamiento automatizado de datos
- â˜ï¸ **Cloud Native** - Optimizado para Google Cloud Platform
- ğŸ”’ **Seguridad** - Rate limiting, autenticaciÃ³n y logging
- ğŸ“ˆ **Escalabilidad** - Arquitectura modular y preparada para producciÃ³n

## ğŸ› ï¸ Tech Stack

- ğŸ **Python 3.10+** - Lenguaje principal
- âš¡ **FastAPI** - Framework web moderno y rÃ¡pido
- ğŸ¤– **Google Vertex AI** - Vector Search y Gemini Pro
- ğŸ” **Google Cloud Platform** - Infraestructura cloud
- ğŸ“Š **Pydantic** - ValidaciÃ³n de datos y serializaciÃ³n
- ğŸ³ **Docker** - ContainerizaciÃ³n
- ğŸ“ **Uvicorn** - Servidor ASGI
- ğŸ” **Httpx** - Cliente HTTP asÃ­ncrono

## ğŸ“ Estructura del Proyecto

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                    # Endpoints de la API
â”‚   â”‚   â””â”€â”€ v1/                # VersiÃ³n 1 de la API
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ chat.py        # Endpoint del chatbot
â”‚   â”‚       â”œâ”€â”€ health.py      # Health check
â”‚   â”‚       â””â”€â”€ ingest.py      # Endpoint de ingesta
â”‚   â”œâ”€â”€ core/                  # ConfiguraciÃ³n y utilidades
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py          # ConfiguraciÃ³n de la aplicaciÃ³n
â”‚   â”‚   â”œâ”€â”€ security.py        # AutenticaciÃ³n y autorizaciÃ³n
â”‚   â”‚   â””â”€â”€ logging.py         # ConfiguraciÃ³n de logging
â”‚   â”œâ”€â”€ models/                # Modelos Pydantic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat.py           # Modelos para el chat
â”‚   â”‚   â””â”€â”€ ingest.py         # Modelos para ingesta
â”‚   â”œâ”€â”€ services/              # LÃ³gica de negocio
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat_service.py   # Servicio del chatbot
â”‚   â”‚   â”œâ”€â”€ vector_service.py # Servicio de bÃºsqueda vectorial
â”‚   â”‚   â””â”€â”€ ingest_service.py # Servicio de ingesta
â”‚   â”œâ”€â”€ utils/                 # Utilidades
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ text_processing.py # Procesamiento de texto
â”‚   â”‚   â””â”€â”€ validators.py      # Validadores personalizados
â”‚   â””â”€â”€ main.py               # Punto de entrada FastAPI
â”œâ”€â”€ scripts/                   # Scripts de utilidad
â”‚   â”œâ”€â”€ extract-i18n-to-json.js # ExtracciÃ³n de traducciones
â”‚   â””â”€â”€ extract-linkedin-profile.js # ExtracciÃ³n de perfil LinkedIn
â”œâ”€â”€ tests/                     # Pruebas unitarias e integraciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_api/             # Tests de endpoints
â”‚   â”œâ”€â”€ test_services/        # Tests de servicios
â”‚   â””â”€â”€ conftest.py           # ConfiguraciÃ³n de pytest
â”œâ”€â”€ requirements.txt           # Dependencias Python
â”œâ”€â”€ requirements-dev.txt       # Dependencias de desarrollo
â”œâ”€â”€ Dockerfile                # Imagen Docker
â”œâ”€â”€ docker-compose.yml        # OrquestaciÃ³n Docker
â”œâ”€â”€ .env.example              # Variables de entorno de ejemplo
â”œâ”€â”€ .env.test                 # Variables de entorno para tests
â””â”€â”€ README.md                 # Este archivo
```

## âš™ï¸ Requisitos

### Software
- Python 3.10 o superior
- pip (gestor de paquetes Python)
- Docker (opcional, para containerizaciÃ³n)

### Servicios Cloud
- Cuenta de Google Cloud Platform
- Proyecto GCP con APIs habilitadas:
  - Vertex AI API
  - Cloud Storage API
  - IAM API
- Credenciales de servicio configuradas

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar y configurar el entorno
```bash
cd backend
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configurar variables de entorno
```bash
cp .env.example .env
```

Edita el archivo `.env` con tus credenciales:
```env
# Google Cloud Configuration
GOOGLE_CLOUD_PROJECT=tu-proyecto-gcp
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json

# Vertex AI Configuration
VERTEX_AI_LOCATION=us-central1
VECTOR_SEARCH_INDEX_ID=tu-index-id
GEMINI_MODEL_NAME=gemini-1.5-pro

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True

# Security
SECRET_KEY=tu-secret-key-super-segura
RATE_LIMIT_PER_MINUTE=60

# Logging
LOG_LEVEL=INFO
```

### 3. Configurar credenciales de Google Cloud
```bash
# OpciÃ³n 1: Usar credenciales de servicio
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account.json"

# OpciÃ³n 2: Usar gcloud CLI
gcloud auth application-default login
```

### 4. Ejecutar el servidor
```bash
# Desarrollo
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# ProducciÃ³n
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

## ğŸ“š API Endpoints

### DocumentaciÃ³n Interactiva
- **Swagger UI**: [http://localhost:8000/docs](http://localhost:8000/docs)
- **ReDoc**: [http://localhost:8000/redoc](http://localhost:8000/redoc)

### Endpoints Principales

#### `GET /api/v1/health`
Health check del servicio
```bash
curl http://localhost:8000/api/v1/health
```

#### `POST /api/v1/chat`
Endpoint principal del chatbot
```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Â¿CuÃ¡les son tus habilidades principales?",
    "session_id": "user-123"
  }'
```

#### `POST /api/v1/ingest`
Ingesta de nuevos datos al sistema RAG
```bash
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Content-Type: application/json" \
  -d '{
    "data_type": "portfolio_update",
    "content": "Nueva informaciÃ³n del portafolio..."
  }'
```

## ğŸ¤– Sistema RAG

### Arquitectura
```
Usuario â†’ Frontend â†’ API â†’ Chat Service â†’ Vector Search â†’ Gemini Pro â†’ Respuesta
```

### Componentes

#### 1. **Vector Search Service**
- BÃºsqueda semÃ¡ntica en embeddings del portafolio
- IntegraciÃ³n con Google Vertex AI Vector Search
- Filtrado y ranking de resultados

#### 2. **Chat Service**
- Procesamiento de consultas del usuario
- ConstrucciÃ³n de prompts contextuales
- IntegraciÃ³n con Gemini Pro para generaciÃ³n

#### 3. **Ingest Service**
- Procesamiento de nuevos datos
- GeneraciÃ³n de embeddings
- ActualizaciÃ³n del Ã­ndice vectorial

### Flujo de Trabajo
1. **Consulta del usuario** llega al endpoint `/chat`
2. **Procesamiento** de la consulta y extracciÃ³n de contexto
3. **BÃºsqueda vectorial** para encontrar informaciÃ³n relevante
4. **ConstrucciÃ³n del prompt** con contexto recuperado
5. **GeneraciÃ³n de respuesta** usando Gemini Pro
6. **Retorno** de la respuesta al usuario

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno Detalladas

```env
# Google Cloud
GOOGLE_CLOUD_PROJECT=tu-proyecto-gcp
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json
VERTEX_AI_LOCATION=us-central1

# Vector Search
VECTOR_SEARCH_INDEX_ID=portfolio-index
VECTOR_SEARCH_DIMENSIONS=768
VECTOR_SEARCH_DISTANCE_MEASURE=cosine

# Gemini Pro
GEMINI_MODEL_NAME=gemini-1.5-pro
GEMINI_MAX_TOKENS=2048
GEMINI_TEMPERATURE=0.7

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True
CORS_ORIGINS=["http://localhost:3000", "https://tu-dominio.com"]

# Security
SECRET_KEY=tu-secret-key-super-segura
RATE_LIMIT_PER_MINUTE=60
API_KEY_HEADER=X-API-Key

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=logs/app.log

# Monitoring
ENABLE_METRICS=True
METRICS_PORT=9090
```

### ConfiguraciÃ³n de Logging
```python
# app/core/logging.py
LOGGING_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "json": {
            "format": "%(asctime)s %(name)s %(levelname)s %(message)s",
            "datefmt": "%Y-%m-%d %H:%M:%S"
        }
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "formatter": "json"
        },
        "file": {
            "class": "logging.FileHandler",
            "filename": "logs/app.log",
            "formatter": "json"
        }
    },
    "root": {
        "level": "INFO",
        "handlers": ["console", "file"]
    }
}
```

## ğŸ§ª Testing

### Instalar dependencias de desarrollo
```bash
pip install -r requirements-dev.txt
```

### Ejecutar tests
```bash
# Tests unitarios
pytest tests/

# Tests con cobertura
pytest --cov=app tests/

# Tests de integraciÃ³n
pytest tests/integration/

# Tests de rendimiento
pytest tests/performance/
```

### ConfiguraciÃ³n de tests
```python
# tests/conftest.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

@pytest.fixture
def client():
    return TestClient(app)

@pytest.fixture
def mock_vertex_ai():
    # Mock de servicios de Vertex AI para tests
    pass
```

## ğŸ³ Docker

### Construir imagen
```bash
docker build -t my-resume-backend .
```

### Ejecutar con Docker
```bash
docker run -p 8000:8000 \
  -e GOOGLE_CLOUD_PROJECT=tu-proyecto \
  -e GOOGLE_APPLICATION_CREDENTIALS=/app/credentials.json \
  -v $(pwd)/credentials.json:/app/credentials.json \
  my-resume-backend
```

### Docker Compose
```bash
# Desarrollo
docker-compose up -d

# ProducciÃ³n
docker-compose -f docker-compose.prod.yml up -d
```

## â˜ï¸ Despliegue en Google Cloud

### Cloud Run (Recomendado)
```bash
# Construir y desplegar
gcloud builds submit --tag gcr.io/PROJECT_ID/my-resume-backend
gcloud run deploy my-resume-backend \
  --image gcr.io/PROJECT_ID/my-resume-backend \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

### App Engine
```bash
# Crear app.yaml
gcloud app deploy
```

### Kubernetes (GKE)
```bash
# Aplicar manifiestos
kubectl apply -f k8s/
```

## ğŸ“Š Monitoreo y Observabilidad

### MÃ©tricas
- Prometheus metrics en `/metrics`
- MÃ©tricas personalizadas de latencia y throughput
- Alertas configurables

### Logging
- Logs estructurados en JSON
- IntegraciÃ³n con Cloud Logging
- Filtros y bÃºsquedas avanzadas

### Tracing
- Distributed tracing con OpenTelemetry
- Trazas de requests completos
- AnÃ¡lisis de performance

## ğŸ”’ Seguridad

### AutenticaciÃ³n
- API Key authentication
- Rate limiting por IP/usuario
- CORS configurado

### ValidaciÃ³n
- ValidaciÃ³n de entrada con Pydantic
- SanitizaciÃ³n de datos
- ProtecciÃ³n contra inyecciÃ³n

### AuditorÃ­a
- Logs de auditorÃ­a
- Tracking de requests
- Alertas de seguridad

## ğŸš€ Performance

### Optimizaciones
- Async/await para operaciones I/O
- Connection pooling
- Caching de embeddings
- CompresiÃ³n de respuestas

### Benchmarks
- Latencia promedio: < 500ms
- Throughput: 1000+ requests/min
- Disponibilidad: 99.9%

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT.

## ğŸ‘¨â€ğŸ’» Autor

**Ãlvaro Maldonado**
- <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/github/github-original.svg" alt="github" width="20" height="20"/> [@aandmaldonado](https://github.com/aandmaldonado)
- <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/linkedin/linkedin-original.svg" alt="linkedin" width="20" height="20"/> [/in/almapidev](https://linkedin.com/in/almapidev)

---

Hecho con â¤ï¸, Python y Google Cloud 